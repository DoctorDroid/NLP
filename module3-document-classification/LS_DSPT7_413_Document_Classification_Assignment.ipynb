{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 1, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification (Assignment)\n",
    "\n",
    "This notebook is for you to practice skills during lecture.\n",
    "\n",
    "Today's guided module project and assignment will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n",
    "\n",
    "Today's all about having fun and practicing your skills.\n",
    "\n",
    "## Sections\n",
    "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
    "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
    "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy\n",
    "* <a href=\"#p4\">Part 4</a>: Post Lecture Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Extraction & Classification Pipelines (Learn)\n",
    "<a id=\"p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along \n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model (try using the pipe method I just demoed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Competition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from scipy.stats import uniform\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4087, 3) (1022, 2)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3861</td>\n",
       "      <td>\\nAn uncommon exclusive bottling of a 6 year o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>\\nThis release is a port version of Amrut’s In...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>\\nThis 41 year old single cask was aged in a s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        description  ratingCategory\n",
       "0  1321  \\nSometimes, when whisky is batched, a few lef...               1\n",
       "1  3861  \\nAn uncommon exclusive bottling of a 6 year o...               0\n",
       "2   655  \\nThis release is a port version of Amrut’s In...               1\n",
       "3   555  \\nThis 41 year old single cask was aged in a s...               1\n",
       "4  1965  \\nQuite herbal on the nose, with aromas of dri...               1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.704918\n",
       "0    0.279178\n",
       "2    0.015904\n",
       "Name: ratingCategory, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of ratingCategory: 0 (Excellent), 1 (Good), 2 (Poor)\n",
    "train.ratingCategory.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>4245</td>\n",
       "      <td>\\nNew distillery in Lancaster, Penn. “Locally sourced” grain, copper pot still, unaged. Rich new-make smell, warm, full grain, rye oil, and anise. Light spirit: sweet, more grain and a character like pizzelles; sweet crisp anise cookies. Easily enjoyed, with a finish of more sweet grain and anise. Interestingly schnapps-like, given the area’s German roots.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3128</th>\n",
       "      <td>4962</td>\n",
       "      <td>\\nAn odd roaring noseful of spices: vanilla, pepper, ginger, teaberry. Tastes perfumey first, then resolves to sweet vanilla, hot oak, and more teaberry. Can’t decide if it wants to be bourbon—it’s hot, and flexing oak—or candy, and does a poor job at both; it’s like a linebacker in a French maid’s outfit, just wrong. There are much better sweet, spicy whiskey mixes out there; the original Spicebox comes to mind.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>4310</td>\n",
       "      <td>\\nLemon-lime gum drops and fresh-cut grass notes, with an underlying creamy, marshmallow-tinged maltiness. Plenty of vanilla, along with a hint of ginger spice zing. Clean, nicely rounded, and fully mature for its age.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "3106  4245   \n",
       "3128  4962   \n",
       "314   4310   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                           description  \\\n",
       "3106  \\nNew distillery in Lancaster, Penn. “Locally sourced” grain, copper pot still, unaged. Rich new-make smell, warm, full grain, rye oil, and anise. Light spirit: sweet, more grain and a character like pizzelles; sweet crisp anise cookies. Easily enjoyed, with a finish of more sweet grain and anise. Interestingly schnapps-like, given the area’s German roots.                                                             \n",
       "3128  \\nAn odd roaring noseful of spices: vanilla, pepper, ginger, teaberry. Tastes perfumey first, then resolves to sweet vanilla, hot oak, and more teaberry. Can’t decide if it wants to be bourbon—it’s hot, and flexing oak—or candy, and does a poor job at both; it’s like a linebacker in a French maid’s outfit, just wrong. There are much better sweet, spicy whiskey mixes out there; the original Spicebox comes to mind.   \n",
       "314   \\nLemon-lime gum drops and fresh-cut grass notes, with an underlying creamy, marshmallow-tinged maltiness. Plenty of vanilla, along with a hint of ginger spice zing. Clean, nicely rounded, and fully mature for its age.                                                                                                                                                                                                         \n",
       "\n",
       "      ratingCategory  \n",
       "3106  0               \n",
       "3128  0               \n",
       "314   0               "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read a few reviews from the \"Excellent\" category\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "train[train.ratingCategory == 0].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>5037</td>\n",
       "      <td>\\nThis is new make from the Rittenhouse Rye mashbill, unaged, right off the still. Yeasty mash notes come through strongly, with a big nose of rye and corn underneath. It smells fresh, and alive. Wow, that’s powerful stuff. Much hotter than the Trybox Corn, this one is on fire with rye spice; it’s got me breaking a sweat! A bit of water brings out more grain notes, and some tempering sweetness, but it’s still no pussycat. Cleanly powerful.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>5059</td>\n",
       "      <td>\\nNasty smell of chicken coop: dried guano, some ammonia, and dust, with grain underneath. Happily, it tastes quite a bit better. Sweet grain, snap of rye spice, some dry cocoa powder, but there's still a dustiness to it, and a distinct small-barrel woodiness. Hard to get past that aroma. Seems like there's more than one problem here.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>5103</td>\n",
       "      <td>\\nThis flavored moonshine smells like a mass of wet, used tea bags. Underneath is some faint lemon, honey, and black pepper, but it’s hard to get to it through the tea. Entry is strong, oversteeped tea, which only gets stronger, more tannic, and more bitter in the mid-palate. Syrupy lemon honey tries and fails to balance this oversteeped mess. Finish is long, bitter, slightly hot, and unpleasant. Do not attempt to drink without copious amounts of crushed ice.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "1849  5037   \n",
       "625   5059   \n",
       "774   5103   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                          description  \\\n",
       "1849  \\nThis is new make from the Rittenhouse Rye mashbill, unaged, right off the still. Yeasty mash notes come through strongly, with a big nose of rye and corn underneath. It smells fresh, and alive. Wow, that’s powerful stuff. Much hotter than the Trybox Corn, this one is on fire with rye spice; it’s got me breaking a sweat! A bit of water brings out more grain notes, and some tempering sweetness, but it’s still no pussycat. Cleanly powerful.                       \n",
       "625   \\nNasty smell of chicken coop: dried guano, some ammonia, and dust, with grain underneath. Happily, it tastes quite a bit better. Sweet grain, snap of rye spice, some dry cocoa powder, but there's still a dustiness to it, and a distinct small-barrel woodiness. Hard to get past that aroma. Seems like there's more than one problem here.                                                                                                                                  \n",
       "774   \\nThis flavored moonshine smells like a mass of wet, used tea bags. Underneath is some faint lemon, honey, and black pepper, but it’s hard to get to it through the tea. Entry is strong, oversteeped tea, which only gets stronger, more tannic, and more bitter in the mid-palate. Syrupy lemon honey tries and fails to balance this oversteeped mess. Finish is long, bitter, slightly hot, and unpleasant. Do not attempt to drink without copious amounts of crushed ice.   \n",
       "\n",
       "      ratingCategory  \n",
       "1849  2               \n",
       "625   2               \n",
       "774   2               "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read a few reviews from the \"Poor\" category\n",
    "train[train.ratingCategory == 2].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Training Set into Train/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3269,) (3269,) (818,) (818,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train['description'], \n",
    "                                                    train['ratingCategory'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    stratify=train['ratingCategory'],\n",
    "                                                    random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2)) #vectorizer\n",
    "clf = LinearSVC() #classifier\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words='english',\n",
       "                                                        strip...\n",
       "                                                  max_iter=1000,\n",
       "                                                  multi_class='ovr',\n",
       "                                                  penalty='l2',\n",
       "                                                  random_state=None, tol=0.0001,\n",
       "                                                  verbose=0))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__C': (0.1, 0.5, 1.0, 2.0),\n",
       "                         'clf__penalty': ('l1', 'l2'),\n",
       "                         'vect__max_df': (0.3, 0.5),\n",
       "                         'vect__max_features': (5000, 20000),\n",
       "                         'vect__min_df': (2, 5, 10)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': (0.3, .5),\n",
    "    'vect__min_df': (2, 5, 10),\n",
    "    'vect__max_features': (5000, 20000),\n",
    "    'clf__penalty': ('l1','l2'),\n",
    "    'clf__C': (0.1, 0.5, 1., 2.)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(train['description'], train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7575254449309149"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cv', 'error_score', 'estimator__memory', 'estimator__steps', 'estimator__verbose', 'estimator__vect', 'estimator__clf', 'estimator__vect__analyzer', 'estimator__vect__binary', 'estimator__vect__decode_error', 'estimator__vect__dtype', 'estimator__vect__encoding', 'estimator__vect__input', 'estimator__vect__lowercase', 'estimator__vect__max_df', 'estimator__vect__max_features', 'estimator__vect__min_df', 'estimator__vect__ngram_range', 'estimator__vect__norm', 'estimator__vect__preprocessor', 'estimator__vect__smooth_idf', 'estimator__vect__stop_words', 'estimator__vect__strip_accents', 'estimator__vect__sublinear_tf', 'estimator__vect__token_pattern', 'estimator__vect__tokenizer', 'estimator__vect__use_idf', 'estimator__vect__vocabulary', 'estimator__clf__C', 'estimator__clf__class_weight', 'estimator__clf__dual', 'estimator__clf__fit_intercept', 'estimator__clf__intercept_scaling', 'estimator__clf__loss', 'estimator__clf__max_iter', 'estimator__clf__multi_class', 'estimator__clf__penalty', 'estimator__clf__random_state', 'estimator__clf__tol', 'estimator__clf__verbose', 'estimator', 'iid', 'n_jobs', 'param_grid', 'pre_dispatch', 'refit', 'return_train_score', 'scoring', 'verbose'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 0.5,\n",
       " 'clf__penalty': 'l2',\n",
       " 'vect__max_df': 0.5,\n",
       " 'vect__max_features': 20000,\n",
       " 'vect__min_df': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File\n",
    "*Note:* In a typical Kaggle competition, you are only allowed two submissions a day, so you only submit if you feel you cannot achieve higher test accuracy. For this competition the max daily submissions are capped at **20**. Submit for each demo and for your assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461  1             \n",
       "1  2604  1             \n",
       "2  3341  1             \n",
       "3  3764  1             \n",
       "4  2306  1             "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "subNumber = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You're trying to achieve a minimum of 70% Accuracy on your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing (Learn)\n",
    "<a id=\"p2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "4. Make a submission to Kaggle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,random_state=0)\n",
    "distributions = dict(C=uniform(loc=0, scale=4),penalty=['l2', 'l1'])\n",
    "RSCV = RandomizedSearchCV(logistic, distributions, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cv', 'error_score', 'estimator__C', 'estimator__class_weight', 'estimator__dual', 'estimator__fit_intercept', 'estimator__intercept_scaling', 'estimator__l1_ratio', 'estimator__max_iter', 'estimator__multi_class', 'estimator__n_jobs', 'estimator__penalty', 'estimator__random_state', 'estimator__solver', 'estimator__tol', 'estimator__verbose', 'estimator__warm_start', 'estimator', 'iid', 'n_iter', 'n_jobs', 'param_distributions', 'pre_dispatch', 'random_state', 'refit', 'return_train_score', 'scoring', 'verbose'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RSCV.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "svd = TruncatedSVD(algorithm='randomized', n_iter=10) \n",
    "rfc = RandomForestClassifier(n_jobs = -1)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('vect', vect),      # TF-IDF Vectorizer\n",
    "    ('svd', svd),        # Truncated SVD Dimensionality Reduction\n",
    "    ('clf', rfc)         # RandomForest Classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_params = {\n",
    "    'clf__max_depth': (10,42,None),\n",
    "    'clf__n_estimators': (11,21,31,41,51),\n",
    "    'clf__max_leaf_nodes':(10,20,30,40,60,80,None),\n",
    "    'vect__max_df': (0.3, .5),\n",
    "    'vect__min_df': (2, 5, 10),\n",
    "    'vect__max_features': (5000, 20000),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1260 candidates, totalling 6300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   41.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2426 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3176 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4026 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4976 tasks      | elapsed: 17.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6026 tasks      | elapsed: 20.8min\n",
      "[Parallel(n_jobs=-1)]: Done 6300 out of 6300 | elapsed: 21.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words='english',\n",
       "                                                        strip...\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__max_depth': (10, 42, None),\n",
       "                         'clf__max_leaf_nodes': (10, 20, 30, 40, 60, 80, None),\n",
       "                         'clf__n_estimators': (11, 21, 31, 41, 51),\n",
       "                         'vect__max_df': (0.3, 0.5),\n",
       "                         'vect__max_features': (5000, 20000),\n",
       "                         'vect__min_df': (2, 5, 10)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSCV_search = GridSearchCV(pipe, g_params, cv=5, n_jobs=-1, verbose=1)\n",
    "GSCV_search.fit(train['description'], train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7154378383554839"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSCV_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_params = {\n",
    "    'clf__max_depth': (10,42,None),\n",
    "    'clf__n_estimators': (11,21,31,41,51),\n",
    "    'clf__max_leaf_nodes':(10,20,30,40,60,80,None),\n",
    "    'vect__max_df': (0.3, .5),\n",
    "    'vect__min_df': (2, 5, 10),\n",
    "    'vect__max_features': (5000, 20000),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   11.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('vect',\n",
       "                                              TfidfVectorizer(analyzer='word',\n",
       "                                                              binary=False,\n",
       "                                                              decode_error='strict',\n",
       "                                                              dtype=<class 'numpy.float64'>,\n",
       "                                                              encoding='utf-8',\n",
       "                                                              input='content',\n",
       "                                                              lowercase=True,\n",
       "                                                              max_df=1.0,\n",
       "                                                              max_features=None,\n",
       "                                                              min_df=1,\n",
       "                                                              ngram_range=(1,\n",
       "                                                                           2),\n",
       "                                                              norm='l2',\n",
       "                                                              preprocessor=None,\n",
       "                                                              smooth_idf=True,\n",
       "                                                              stop_words='english'...\n",
       "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'clf__max_depth': (10, 42, None),\n",
       "                                        'clf__max_leaf_nodes': (10, 20, 30, 40,\n",
       "                                                                60, 80, None),\n",
       "                                        'clf__n_estimators': (11, 21, 31, 41,\n",
       "                                                              51),\n",
       "                                        'vect__max_df': (0.3, 0.5),\n",
       "                                        'vect__max_features': (5000, 20000),\n",
       "                                        'vect__min_df': (2, 5, 10)},\n",
       "                   pre_dispatch='2*n_jobs', random_state=17, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rando_search = RandomizedSearchCV(pipe, r_params, cv=5, n_jobs=-1, verbose=1, random_state = 17)\n",
    "rando_search.fit(train['description'], train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cv', 'error_score', 'estimator__memory', 'estimator__steps', 'estimator__verbose', 'estimator__vect', 'estimator__svd', 'estimator__clf', 'estimator__vect__analyzer', 'estimator__vect__binary', 'estimator__vect__decode_error', 'estimator__vect__dtype', 'estimator__vect__encoding', 'estimator__vect__input', 'estimator__vect__lowercase', 'estimator__vect__max_df', 'estimator__vect__max_features', 'estimator__vect__min_df', 'estimator__vect__ngram_range', 'estimator__vect__norm', 'estimator__vect__preprocessor', 'estimator__vect__smooth_idf', 'estimator__vect__stop_words', 'estimator__vect__strip_accents', 'estimator__vect__sublinear_tf', 'estimator__vect__token_pattern', 'estimator__vect__tokenizer', 'estimator__vect__use_idf', 'estimator__vect__vocabulary', 'estimator__svd__algorithm', 'estimator__svd__n_components', 'estimator__svd__n_iter', 'estimator__svd__random_state', 'estimator__svd__tol', 'estimator__clf__bootstrap', 'estimator__clf__ccp_alpha', 'estimator__clf__class_weight', 'estimator__clf__criterion', 'estimator__clf__max_depth', 'estimator__clf__max_features', 'estimator__clf__max_leaf_nodes', 'estimator__clf__max_samples', 'estimator__clf__min_impurity_decrease', 'estimator__clf__min_impurity_split', 'estimator__clf__min_samples_leaf', 'estimator__clf__min_samples_split', 'estimator__clf__min_weight_fraction_leaf', 'estimator__clf__n_estimators', 'estimator__clf__n_jobs', 'estimator__clf__oob_score', 'estimator__clf__random_state', 'estimator__clf__verbose', 'estimator__clf__warm_start', 'estimator', 'iid', 'n_iter', 'n_jobs', 'param_distributions', 'pre_dispatch', 'random_state', 'refit', 'return_train_score', 'scoring', 'verbose'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rando_search.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vect__min_df': 2,\n",
       " 'vect__max_features': 5000,\n",
       " 'vect__max_df': 0.3,\n",
       " 'clf__n_estimators': 31,\n",
       " 'clf__max_leaf_nodes': 80,\n",
       " 'clf__max_depth': 10}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rando_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7105445709001565"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rando_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = rando_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = rando_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461  1             \n",
       "1  2604  1             \n",
       "2  3341  1             \n",
       "3  3764  1             \n",
       "4  2306  1             "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = GSCV_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461  1             \n",
       "1  2604  1             \n",
       "2  3341  1             \n",
       "3  3764  1             \n",
       "4  2306  1             "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings with Spacy (Learn)\n",
    "<a id=\"p3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to your Dataset\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.stats import randint\n",
    "import scipy.stats as stats\n",
    "# Use parameters from GridSearch in previous section\n",
    "vect = TfidfVectorizer(parameters)\n",
    "\n",
    "# Add dimensionality reduction\n",
    "svd = TruncatedSVD(algorithm='randomized',\n",
    "                   n_iter=10)\n",
    "\n",
    "# Use parameters from RandomSearch in previous section\n",
    "clf = LinearSVC(C=1.0, class_weight=None, dual=True,\n",
    "                           fit_intercept=True, intercept_scaling=1,\n",
    "                           loss='squared_hinge', max_iter=1000,\n",
    "                           multi_class='ovr', penalty='l2', random_state=None,\n",
    "                           tol=0.0001, verbose=0)\n",
    "param_dist = {\n",
    "    'max_depth' : randint(3,10),\n",
    "    'min_samples_leaf': randint(2,15)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['emb'] = train['description'].apply(lambda text: nlp(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['emb'] = test['description'].apply(lambda text: nlp(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "C:\\Python\\Anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2)) #vectorizer\n",
    "clf = LinearSVC() #classifier\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', clf)])\n",
    "parameters = {\n",
    "    'vect__max_df': (0.3, .5),\n",
    "    'vect__min_df': (2, 5, 10),\n",
    "    'vect__max_features': (5000, 20000),\n",
    "    'clf__penalty': ('l1','l2'),\n",
    "    'clf__C': (0.1, 0.5, 1., 2.)\n",
    "}\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(train['emb'], train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = ...predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "submission.to_csv(f'./whiskey-reviews-dspt7/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
    "4. Make a submission to Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Lecture Assignment\n",
    "<a id=\"p4\"></a>\n",
    "\n",
    "Your primary assignment this afternoon is to achieve a minimum of 70% accuracy on the Kaggle competition. Once you have achieved 70% accuracy, please work on the following: \n",
    "\n",
    "1. Research \"Sentiment Analysis\". Provide answers in markdown to the following questions: \n",
    "    - What is \"Sentiment Analysis\"? \n",
    "    - Is Document Classification different than \"Sentiment Analysis\"? Provide evidence for your response\n",
    "    - How do create labeled sentiment data? Are those labels really sentiment?\n",
    "    - What are common applications of sentiment analysis?\n",
    "2. Research our why word embeddings worked better for the lecture notebook than on the whiskey competition.\n",
    "    - This [text classification documentation](https://developers.google.com/machine-learning/guides/text-classification/step-2-5) from Google might be of interest\n",
    "    - Neural Networks are becoming more popular for document classification. Why is that the case?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
